{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5683d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "NEWSPAPER = 'Fox'\n",
    "SECTIONS = ['entertainment', 'politics', 'us', 'world']\n",
    "NEWSPAPER_URL = \"https://www.foxnews.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0d550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('db_current.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2178f20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2212"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_body_collected = list(db['link_to_original'].values)\n",
    "len(article_body_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa61698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2023_03_28\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "today = str(today).replace('-', '_')\n",
    "print(\"Today's date:\", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7334f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_today = ['WSJ', 'NYT']\n",
    "for scraped_file in scraped_today:\n",
    "    scraped_file_name = scraped_file + '_' + today + '.csv'\n",
    "    temp_df = pd.read_csv('scrape_results\\\\' + today + '\\\\' + scraped_file_name)\n",
    "    scraped_today_links = list(temp_df['link_to_original'].values)\n",
    "    article_body_collected += scraped_today_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d8a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2379"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_body_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "315af9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2286"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_body_collected_set = set(article_body_collected)\n",
    "len(article_body_collected_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ed8e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2286"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_body_collected = list(article_body_collected_set)\n",
    "len(article_body_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c6ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fox_extract_article(article_link):\n",
    "    web = requests.get(article_link)\n",
    "    article_content = soup(web.content,'html.parser')\n",
    "    \n",
    "    article_content_processed = article_content.find(\"script\", {\"type\": \"application/ld+json\"})\n",
    "    article_title = json.loads(article_content_processed.text)['headline']\n",
    "    article_dt = json.loads(article_content_processed.text)['datePublished'].split('T')[0]\n",
    "    article_time = int(pd.to_datetime(json.loads(article_content_processed.text)['datePublished']).timestamp()) * 1000\n",
    "    \n",
    "    article_body = ''\n",
    "    paragraphs = article_content.find(\"div\", {\"class\": 'article-body'}).find_all('p')\n",
    "    for p in paragraphs:\n",
    "        if 'a href' and '<strong>' in str(p):\n",
    "            pass\n",
    "        elif '@fox.com' in str(p):\n",
    "            pass\n",
    "        elif ('Fox News\\'' in str(p) and 'contributed to this report.' in str(p)):\n",
    "            pass\n",
    "        elif 'span' in str(p):\n",
    "            pass\n",
    "        else:\n",
    "            #print(p.text)\n",
    "            article_body += p.text + ' '\n",
    "\n",
    "    return(article_title, article_body, article_dt, article_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c4ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_article_title = []\n",
    "list_article_link = []\n",
    "list_article_body = []\n",
    "list_article_dt = []\n",
    "list_article_time = []\n",
    "list_article_section = []\n",
    "\n",
    "for section in SECTIONS:\n",
    "    newspaper_section_url = NEWSPAPER_URL + \"/\" + section\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    web = requests.get(newspaper_section_url, headers=headers)\n",
    "    section_content = soup(web.content,'html.parser')\n",
    "    \n",
    "    articles = section_content.find_all(\"article\", {\"class\": 'article'})\n",
    "    for article in articles:\n",
    "        if 'foxnews.com' in str(article.find('a')).split('<a href=\\\"')[1].split('\\\"><')[0]:\n",
    "            article_link_ending = article_link_ending.split('foxnews.com')[0]\n",
    "        else:\n",
    "            article_link_ending = str(article.find('a')).split('<a href=\\\"')[1].split('\\\"><')[0]\n",
    "        article_link = NEWSPAPER_URL + article_link_ending\n",
    "        #article_link = article_link.replace('//', '/')\n",
    "        if article_link in article_body_collected:\n",
    "            pass\n",
    "        else:\n",
    "            if article_link in list_article_link:\n",
    "                index_of_interest = list_article_link.index(article_link)\n",
    "                if isinstance(list_article_section[index_of_interest], list):\n",
    "                    if section in list_article_section[index_of_interest]:\n",
    "                        pass\n",
    "                elif section == list_article_section[index_of_interest]:\n",
    "                        pass\n",
    "                else:\n",
    "                    if isinstance(list_article_section[index_of_interest], list):\n",
    "                        list_article_section[index_of_interest].append(section)\n",
    "                    else:\n",
    "                        new_list = [list_article_section[index_of_interest]]\n",
    "                        new_list.append(section)\n",
    "                        list_article_section[index_of_interest] = new_list\n",
    "            else:\n",
    "                if ('/video/' not in article_link and\n",
    "                    '/opinion/' not in article_link and\n",
    "                    '/media/' not in article_link and\n",
    "                    '/entertainment/' not in article_link and\n",
    "                    '/sports/' not in article_link and\n",
    "                    '/lifestyle/' not in article_link):\n",
    "\n",
    "                    # print(article_link)\n",
    "                    article_title, article_body, article_dt, article_time = fox_extract_article(article_link)\n",
    "\n",
    "                    list_article_title.append(article_title)\n",
    "                    list_article_link.append(article_link)\n",
    "                    list_article_body.append(article_body)\n",
    "                    list_article_dt.append(article_dt)\n",
    "                    list_article_time.append(article_time)\n",
    "                    list_article_section.append(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33486624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/world/britain-overhaul-clinical-trial-regulation-fast-track-approvals'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_link_ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7277bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/world/britain-overhaul-clinical-trial-regulation-fast-track-approvals']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_link_ending.split('foxnews.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a5cc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dict = {'title':list_article_title,\n",
    "    'link_to_original':list_article_link,\n",
    "    'article_body':list_article_body,\n",
    "    'article_dt':list_article_dt,\n",
    "    'article_time':list_article_time,\n",
    "    'section': list_article_section,\n",
    "   }\n",
    "    \n",
    "df = pd.DataFrame(articles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67b4b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = NEWSPAPER + '_' + today + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276fc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('\\\\scrape_results\\\\' + today + '\\\\' + filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
